{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_1_Classification_BatchGD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "jdFGdXW_0c_X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Tutorial: Neural Network for Classification using simple Gradient Descent.\n",
        "\n",
        "### Author: Ivan Bongiorni, Data Scientist at GfK.\n",
        "\n",
        "[LinkedIn profile](https://www.linkedin.com/in/ivan-bongiorni-b8a583164/), personal email: ivanbongiorni@gmail.com\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CiCwmEFVIfXL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model is a **Neural Network for Classification** based on the University of Wisconsin's **breast cancer dataset**.\n",
        "\n",
        "It represents a tutorial on basic **TensorFlow**.\n",
        "\n",
        "Arguments:\n",
        "1.   Download of the dataset and Dataprep,\n",
        "2.   Implementation of a \"simple\" **feed-forward Neural Network for classification** in plain **TensorFlow**,\n",
        "3.   Implementation of a **simple Batch Gradient Descent** optimization algorithm - with **dropout** and **batch normalization** as regularization techniques,\n",
        "4.   Check of results using data-visualization and a Confusion Matrix."
      ]
    },
    {
      "metadata": {
        "id": "FmGeevua2Jzf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import data from UCI ML repository\n",
        "\n",
        "The purpose of this dataset is to classify breast cancer cases between **malignant** (**M**), and **benign** (**B**). Therefore, my classification network will have two output nodes."
      ]
    },
    {
      "metadata": {
        "id": "6cb_bMog8kXc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "bc_dat = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\", sep=\",\", header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HTXgNVxD2VYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Some (vey basic) Dataprep"
      ]
    },
    {
      "metadata": {
        "id": "QcevSCqu385u",
        "colab_type": "code",
        "outputId": "666908c9-1be2-49dd-9bda-d2585da2d426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# First take a look at the data\n",
        "bc_dat.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "C2MtcQoJ21L5",
        "colab_type": "code",
        "outputId": "f8409511-18b3-4a96-e17a-e08e3be1849e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)  # this command makes pandas show all the columns\n",
        "\n",
        "bc_dat.describe()  # columns 1 is not present, since it's not numeric"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0           2           3           4            5   \\\n",
              "count  5.690000e+02  569.000000  569.000000  569.000000   569.000000   \n",
              "mean   3.037183e+07   14.127292   19.289649   91.969033   654.889104   \n",
              "std    1.250206e+08    3.524049    4.301036   24.298981   351.914129   \n",
              "min    8.670000e+03    6.981000    9.710000   43.790000   143.500000   \n",
              "25%    8.692180e+05   11.700000   16.170000   75.170000   420.300000   \n",
              "50%    9.060240e+05   13.370000   18.840000   86.240000   551.100000   \n",
              "75%    8.813129e+06   15.780000   21.800000  104.100000   782.700000   \n",
              "max    9.113205e+08   28.110000   39.280000  188.500000  2501.000000   \n",
              "\n",
              "               6           7           8           9           10          11  \\\n",
              "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000   \n",
              "mean     0.096360    0.104341    0.088799    0.048919    0.181162    0.062798   \n",
              "std      0.014064    0.052813    0.079720    0.038803    0.027414    0.007060   \n",
              "min      0.052630    0.019380    0.000000    0.000000    0.106000    0.049960   \n",
              "25%      0.086370    0.064920    0.029560    0.020310    0.161900    0.057700   \n",
              "50%      0.095870    0.092630    0.061540    0.033500    0.179200    0.061540   \n",
              "75%      0.105300    0.130400    0.130700    0.074000    0.195700    0.066120   \n",
              "max      0.163400    0.345400    0.426800    0.201200    0.304000    0.097440   \n",
              "\n",
              "               12          13          14          15          16          17  \\\n",
              "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000   \n",
              "mean     0.405172    1.216853    2.866059   40.337079    0.007041    0.025478   \n",
              "std      0.277313    0.551648    2.021855   45.491006    0.003003    0.017908   \n",
              "min      0.111500    0.360200    0.757000    6.802000    0.001713    0.002252   \n",
              "25%      0.232400    0.833900    1.606000   17.850000    0.005169    0.013080   \n",
              "50%      0.324200    1.108000    2.287000   24.530000    0.006380    0.020450   \n",
              "75%      0.478900    1.474000    3.357000   45.190000    0.008146    0.032450   \n",
              "max      2.873000    4.885000   21.980000  542.200000    0.031130    0.135400   \n",
              "\n",
              "               18          19          20          21          22          23  \\\n",
              "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000   \n",
              "mean     0.031894    0.011796    0.020542    0.003795   16.269190   25.677223   \n",
              "std      0.030186    0.006170    0.008266    0.002646    4.833242    6.146258   \n",
              "min      0.000000    0.000000    0.007882    0.000895    7.930000   12.020000   \n",
              "25%      0.015090    0.007638    0.015160    0.002248   13.010000   21.080000   \n",
              "50%      0.025890    0.010930    0.018730    0.003187   14.970000   25.410000   \n",
              "75%      0.042050    0.014710    0.023480    0.004558   18.790000   29.720000   \n",
              "max      0.396000    0.052790    0.078950    0.029840   36.040000   49.540000   \n",
              "\n",
              "               24           25          26          27          28  \\\n",
              "count  569.000000   569.000000  569.000000  569.000000  569.000000   \n",
              "mean   107.261213   880.583128    0.132369    0.254265    0.272188   \n",
              "std     33.602542   569.356993    0.022832    0.157336    0.208624   \n",
              "min     50.410000   185.200000    0.071170    0.027290    0.000000   \n",
              "25%     84.110000   515.300000    0.116600    0.147200    0.114500   \n",
              "50%     97.660000   686.500000    0.131300    0.211900    0.226700   \n",
              "75%    125.400000  1084.000000    0.146000    0.339100    0.382900   \n",
              "max    251.200000  4254.000000    0.222600    1.058000    1.252000   \n",
              "\n",
              "               29          30          31  \n",
              "count  569.000000  569.000000  569.000000  \n",
              "mean     0.114606    0.290076    0.083946  \n",
              "std      0.065732    0.061867    0.018061  \n",
              "min      0.000000    0.156500    0.055040  \n",
              "25%      0.064930    0.250400    0.071460  \n",
              "50%      0.099930    0.282200    0.080040  \n",
              "75%      0.161400    0.317900    0.092080  \n",
              "max      0.291000    0.663800    0.207500  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "S2LHhMma23ZB",
        "colab_type": "code",
        "outputId": "d66799c8-8dcc-4a83-bc33-25523cbca574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "cell_type": "code",
      "source": [
        "bc_dat.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0  1      2      3       4       5        6        7       8   \\\n",
              "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
              "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
              "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
              "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
              "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
              "\n",
              "        9       10       11      12      13     14      15        16       17  \\\n",
              "0  0.14710  0.2419  0.07871  1.0950  0.9053  8.589  153.40  0.006399  0.04904   \n",
              "1  0.07017  0.1812  0.05667  0.5435  0.7339  3.398   74.08  0.005225  0.01308   \n",
              "2  0.12790  0.2069  0.05999  0.7456  0.7869  4.585   94.03  0.006150  0.04006   \n",
              "3  0.10520  0.2597  0.09744  0.4956  1.1560  3.445   27.23  0.009110  0.07458   \n",
              "4  0.10430  0.1809  0.05883  0.7572  0.7813  5.438   94.44  0.011490  0.02461   \n",
              "\n",
              "        18       19       20        21     22     23      24      25      26  \\\n",
              "0  0.05373  0.01587  0.03003  0.006193  25.38  17.33  184.60  2019.0  0.1622   \n",
              "1  0.01860  0.01340  0.01389  0.003532  24.99  23.41  158.80  1956.0  0.1238   \n",
              "2  0.03832  0.02058  0.02250  0.004571  23.57  25.53  152.50  1709.0  0.1444   \n",
              "3  0.05661  0.01867  0.05963  0.009208  14.91  26.50   98.87   567.7  0.2098   \n",
              "4  0.05688  0.01885  0.01756  0.005115  22.54  16.67  152.20  1575.0  0.1374   \n",
              "\n",
              "       27      28      29      30       31  \n",
              "0  0.6656  0.7119  0.2654  0.4601  0.11890  \n",
              "1  0.1866  0.2416  0.1860  0.2750  0.08902  \n",
              "2  0.4245  0.4504  0.2430  0.3613  0.08758  \n",
              "3  0.8663  0.6869  0.2575  0.6638  0.17300  \n",
              "4  0.2050  0.4000  0.1625  0.2364  0.07678  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "xHedMVzY3uQo",
        "colab_type": "code",
        "outputId": "e6a5b58f-4bfe-419e-a1f7-0e4fba9cfc98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's check the dependent variable:\n",
        "bc_dat.iloc[:,1].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     569\n",
              "unique      2\n",
              "top         B\n",
              "freq      357\n",
              "Name: 1, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "8MZswZsz2POl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The first column [0] is a simple id - and must be discarded\n",
        "# I then separate explanatory variables (matrix of independent vairables IVs) and the vector of the dependent variable (DV) that contains the target categories\n",
        "\n",
        "IVs = bc_dat.iloc[:,2:31]\n",
        "\n",
        "DV = bc_dat.iloc[:,1]\n",
        "DV = pd.get_dummies(DV)  # One-Hot Encoding - required by classification algorithms\n",
        "\n",
        "# In order to feed the data into a Neural Network, I must turn the data into numpy objects\n",
        "IVs = IVs.values\n",
        "DV = DV.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_US9T10bMPOA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Scale the variables using Z-scores\n",
        "# you can use sklearn's preprocessing.StandardScaler() if you prefer\n",
        "\n",
        "def normalize(x):\n",
        "    return (x - np.mean(x))/(np.std(x))\n",
        "\n",
        "for i in range(IVs.shape[1]):\n",
        "    IVs[:,i] = normalize(IVs[:,i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "na1-bLe4476t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train-Test split\n",
        "\n",
        "In an actual ML job, you would split your dataset in **Train**, **Test**, and **Validation sets**. However, this is just an example on how to implement and run a Neural Network, so I'll skip that part and will split the data in train and test only."
      ]
    },
    {
      "metadata": {
        "id": "W8V-cHX21C_R",
        "colab_type": "code",
        "outputId": "f43f4c87-e654-4fc2-cf3c-e27304732807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(IVs, DV, test_size=0.25, random_state=173)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 29) (426, 2)\n",
            "(143, 29) (143, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ixixVy6OHfgs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Architecture\n",
        "\n",
        "Since the network is not very deep, and the number of parameters is relatively small, I can employ more \"demanding\" (and performing) activation functions. In this case, I choose **Leaky ReLU** for hidden layers. A **softmax** function is then applied at the end, so that the attribution of classes (M/B) is shrink into probabilities.\n",
        "\n",
        "I also applied **dropout**, that helps prevent overfitting; and **Batch normalization**, that prevents the problem of vanishing/expoloding gradients.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Rah6V2pW8qa5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# The fully_connected function generates the layers of Neural Networks\n",
        "from tensorflow.contrib.layers import fully_connected, batch_norm\n",
        "\n",
        "# I choose the size of each layer\n",
        "n_inputs = X_train.shape[1]\n",
        "n_hidden1 = 30\n",
        "n_hidden2 = 30\n",
        "n_hidden3 = 15\n",
        "n_hidden4 = 15\n",
        "n_outputs = 2   # Number of outputs: \"Malignant\" or \"Benign\"\n",
        "\n",
        "dropout_probability = 0.1\n",
        "\n",
        "# Placeholders are kind of \"empty variables\" in a TF computational graph.\n",
        "# I will feed the actual data through them - in the graph, they are like entry doors for my data\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, n_outputs), name=\"y\")\n",
        "\n",
        "\n",
        "hidden1 = fully_connected(X, n_hidden1, activation_fn=tf.nn.leaky_relu, normalizer_fn=batch_norm, scope=\"hidden1\")\n",
        "hidden1 = tf.layers.dropout(hidden1, rate=dropout_probability)\n",
        "\n",
        "hidden2 = fully_connected(hidden1, n_hidden2, activation_fn=tf.nn.leaky_relu, normalizer_fn=batch_norm, scope=\"hidden2\")\n",
        "hidden2 = tf.layers.dropout(hidden2, rate=dropout_probability)\n",
        "\n",
        "hidden3 = fully_connected(hidden2, n_hidden3, activation_fn=tf.nn.leaky_relu, normalizer_fn=batch_norm, scope=\"hidden3\")\n",
        "hidden3 = tf.layers.dropout(hidden3, rate=dropout_probability)\n",
        "\n",
        "hidden4 = fully_connected(hidden3, n_hidden4, activation_fn=tf.nn.leaky_relu, normalizer_fn=batch_norm, scope=\"hidden4\")\n",
        "hidden4 = tf.layers.dropout(hidden4, rate=dropout_probability)\n",
        "\n",
        "# this is the output layer - I choose a softmax function that shrinks everything into probabilities\n",
        "classes = fully_connected(hidden3, n_outputs, activation_fn=tf.nn.softmax, scope=\"outputs\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rbjnKz1S8yNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define a loss function - softmax cross entropy is very common for classification tasks\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=classes))\n",
        "\n",
        "\n",
        "# this node of the TF graph performs the actual training process\n",
        "training_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
        "\n",
        "# I define also a measure of accuracy - so that I can monitor how it changes \n",
        "correct = tf.equal(tf.argmax(classes, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkGseeqn6pmq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementation of Batch Gradient Descent\n",
        "\n",
        "This implementation is the simplest form of feed-forward Neural Network, based on **batch Gradient Descent**. This is Gradient Descent in its simplest form, in which the whole bunch of training data is fed into the network at each iteration.\n",
        "\n",
        "In a following notebook I will show the implementation of **Mini-Batch Gradient Descent**."
      ]
    },
    {
      "metadata": {
        "id": "yKLFel2f99bW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# I first set a saver, in order to save the model\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Training usually requires a higher number of epochs - this is just a toy model for explanation purposes\n",
        "n_epochs = 3000\n",
        "\n",
        "# I want to save loss, train and test accuracy at each epoch\n",
        "loss_train_history = []\n",
        "loss_test_history = []\n",
        "accuracy_train_history = []\n",
        "accuracy_test_history = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmFNdatO7WKf",
        "colab_type": "code",
        "outputId": "cb1b34f6-548a-4e25-a8ef-75d50ce299e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# I now open a TensorFlow session, in order to execute the computational graph\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    # the the beginning of each execution, you must initialize all variables in the computational graph\n",
        "    sess.run(tf.global_variables_initializer())   # if the computational graph was a motor, this would turn it on\n",
        "    \n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        # this is the training. I feed my train data to optimize the loss function\n",
        "        sess.run(training_op, feed_dict={X: X_train, y: y_train})   # I can do it because I defined the X and y placeholders above\n",
        "        \n",
        "        # then save loss, train and test accuracy\n",
        "        # each accuracy/loss requires train/test data for its computation\n",
        "        loss_train = loss.eval(feed_dict={X: X_train, y: y_train})\n",
        "        loss_test = loss.eval(feed_dict={X: X_test, y: y_test})\n",
        "        accuracy_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
        "        accuracy_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        \n",
        "        # then add them to the series\n",
        "        loss_train_history.append(loss_train)\n",
        "        loss_test_history.append(loss_test)\n",
        "        accuracy_train_history.append(accuracy_train)\n",
        "        accuracy_test_history.append(accuracy_test)\n",
        "        \n",
        "        # Print the losses and monitor the training process in real time\n",
        "        # In this example, I don't want to print 1000 rows (this would make the notebook unreadable), so I'll just print one every 100 epochs:\n",
        "        if epoch % 100 == 0:\n",
        "            print(str(epoch+1) + \". Train accuracy: \" + str(accuracy_train) + \"; Test accuracy: \" + str(accuracy_test) + \",\")\n",
        "            \n",
        "            # additionally, the following line saves the model every 100 iterations\n",
        "            # In case the training takes very long, you want to save the model periodically, so you don't run the risk to loose your progress\n",
        "            saver.save(sess, \"TF_classification.ckpt\")   # the \"./\" means \"in the current directory\" - classification.ckpt is my TF model\n",
        "    \n",
        "    # At the very end, I save the model:\n",
        "    saver.save(sess, \"TF_classification.ckpt\")\n",
        "    \n",
        "    # and I store the predictions for the test set in an object:\n",
        "    prediction = classes.eval(feed_dict={X: X_test, y: y_test})  # I use classes, because that's the output of the Network\n",
        "    \n",
        "    print()\n",
        "    print(\"Training complete.\")\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. Train accuracy: 0.5; Test accuracy: 0.48251748,\n",
            "101. Train accuracy: 0.9882629; Test accuracy: 0.97902095,\n",
            "201. Train accuracy: 0.9906103; Test accuracy: 0.986014,\n",
            "301. Train accuracy: 0.9976526; Test accuracy: 0.986014,\n",
            "401. Train accuracy: 1.0; Test accuracy: 0.986014,\n",
            "501. Train accuracy: 1.0; Test accuracy: 0.986014,\n",
            "601. Train accuracy: 1.0; Test accuracy: 0.986014,\n",
            "701. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "801. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "901. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1001. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1101. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1201. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1301. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1401. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1501. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1601. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1701. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1801. Train accuracy: 1.0; Test accuracy: 0.97902095,\n",
            "1901. Train accuracy: 1.0; Test accuracy: 0.97202796,\n",
            "2001. Train accuracy: 1.0; Test accuracy: 0.97202796,\n",
            "2101. Train accuracy: 1.0; Test accuracy: 0.97202796,\n",
            "2201. Train accuracy: 1.0; Test accuracy: 0.97202796,\n",
            "2301. Train accuracy: 1.0; Test accuracy: 0.97202796,\n",
            "2401. Train accuracy: 1.0; Test accuracy: 0.97202796,\n",
            "2501. Train accuracy: 1.0; Test accuracy: 0.96503496,\n",
            "2601. Train accuracy: 1.0; Test accuracy: 0.96503496,\n",
            "2701. Train accuracy: 1.0; Test accuracy: 0.96503496,\n",
            "2801. Train accuracy: 1.0; Test accuracy: 0.96503496,\n",
            "2901. Train accuracy: 1.0; Test accuracy: 0.96503496,\n",
            "\n",
            "Training complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sZ30S7lTPgKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**( IMPORTANT CLARIFICATION**: *In this notebook I saved, at the end of the training process, the model's predictions of the Network on the test set in a specific object (prediction). This is done for educational purposes only, but it's not a good practice for Data Scientists. In a following notebook, I will show how to **restore a model** and use it for prediction after the training is done.* )"
      ]
    },
    {
      "metadata": {
        "id": "fwL6PbMwN4GV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check performance visually"
      ]
    },
    {
      "metadata": {
        "id": "oRuUyW_yESzz",
        "colab_type": "code",
        "outputId": "41e90ce1-2bf1-4e0c-f15c-0cb7964daaa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(loss_train_history, label='Train loss')\n",
        "plt.plot(loss_test_history, label='Test loss')\n",
        "plt.title('Train and Test loss - Batch Gradient Descent')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NfibKr7-Gpb4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What can be noted is some overfitting: the training model slightly outperforms the test model. However, this difference doesn't seeem to be too high."
      ]
    },
    {
      "metadata": {
        "id": "HSXIxbrZEA7-",
        "colab_type": "code",
        "outputId": "37406893-3532-439e-dfb5-fe3f15e4d6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(accuracy_train_history, label='Train accuracy')\n",
        "plt.plot(accuracy_test_history, label='Test accuracy')\n",
        "plt.title('Train and Test accuracy - Batch Gradient Descent')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRGQj/w8EmQZ5vb7NdQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4WNpYCjuJ2lW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now I'd like to check a Confusion Matrix:\n"
      ]
    },
    {
      "metadata": {
        "id": "wA0OYxBPOF3S",
        "colab_type": "code",
        "outputId": "48e2201b-1ce1-40bd-c50a-8e3c5810ea1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# First, I need to transform the predictions of the Network in discrete probabilities\n",
        "# that is because my prediction object contains float data. Instead, I need discrete [0 or 1] values for classification\n",
        "# There are several ways, this is just one of the many\n",
        "discrete_prediction = prediction\n",
        "\n",
        "discrete_prediction = np.argmax(prediction, axis=1)   # this outputs a vector with the value of the class with the highest predicted probability [0 or 1]\n",
        "discrete_testdata = np.argmax(y_test, axis=1)    # so I do it also for the test data\n",
        "\n",
        "# plot the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "CM = confusion_matrix(discrete_prediction, discrete_testdata)\n",
        "print(CM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[89  5]\n",
            " [ 0 49]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JzalO-eIOUpn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The outcome of the Confusion Matrix seems very good. Most of the cases are on the have been classified correctly, i.e.: they are on the diagonal.\n",
        "\n",
        "We can also plot it as a heatmap, which can be very useful in case you are working with a high number of classes."
      ]
    },
    {
      "metadata": {
        "id": "O7vmy4Y6Od_o",
        "colab_type": "code",
        "outputId": "7dcc0920-f345-4065-84b4-09948bdaafd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn\n",
        "\n",
        "seaborn.heatmap(CM, annot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdff39a9dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAAFKCAYAAABme+rbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFXlJREFUeJzt3Xtw1eWdx/HPL5yGXKhcYk64BhG5\npAQU7NhGYCQQB0UrME5oipJBXWYpC14ohXARlUgootYF0uJCwcEEzRqtpe3S0LViaxsC6CqG2lLo\nCiFALoAGSIISzv7RnVQGzUmOz+E84Xm/nDPDOfB78uUfPn6f5/v7HS8QCAQEAMAVLirSBQAAcDkQ\neAAAJxB4AAAnEHgAACcQeAAAJxB4AAAn+ML9A4b1vSXcPwIIu9I/box0CYAR8b37h23tr/Lv/d5D\nbxms5IuFPfAAAG7wPC/SJbSILU0AgBPo8AAARnie3T2U3dUBAGAIHR4AwIgo2X2GR+ABAIywfWiF\nwAMAGBFl+RkegQcAMML2Ds/uOAYAwBACDwDgBLY0AQBGeExpAgBcwNAKAMAJtg+tEHgAACOiLA88\nu/tPAAAMIfAAAE5gSxMAYIRneQ9F4AEAjGBoBQDgBNuHVgg8AIARtt94bveGKwAAhhB4AAAnsKUJ\nADCCR4sBAJzAlCYAwAlMaQIAnMCUJgAAFqDDAwAYYfvQit3VAQBgCB0eAMAIpjQBAE5gShMA4ASm\nNAEAsAAdHgDACM7wAABOsP0Mjy1NAIAT6PAAAEbYPrRC4AEAjOBJKwAAWIAODwBgBFOaAAAn2D6l\nSeABAIxgaAUAgK/glVde0datW5vfl5eXKzU1VfX19YqLi5MkLViwQKmpqS2uQ+ABAIwI15ZmZmam\nMjMzJUm7du3Stm3bdODAAa1YsUIDBw5sfX1hqQ4AgDDIz8/XrFmzQrqWDg8AYES4pzT37t2rHj16\nKDExUZK0evVqnTp1Sv3799eiRYsUExPT4vV0eAAAI6I8L+RXaxQXF2vy5MmSpOzsbM2fP1+FhYXy\nPE+FhYXB6/tKfzsAAP6f9xX+a42ysjINHz5cknTrrbcqOTlZkjR27Fjt378/6PUEHgDAiHB2eFVV\nVYqPj1d0dLQCgYCmT5+uuro6Sf8IwgEDBgRdgzM8AID1ampq1K1bN0n/OCucMmWKpk+frtjYWCUl\nJWnOnDlB1yDwAADWS01N1YYNG5rfT5gwQRMmTGjTGgQeAMAInqUJAHACz9IEADiBZ2kCAJxge4fH\nbQkAACcQeAAAJ7ClCQAwgilNAIATbD/DI/AAAEbQ4QEAnGD7bQkMrQAAnECHBwAwIsruBo8ODwDg\nBjo8AIARDK0AAJzAbQkAACfY3uFxhgcAcAIdXjszMfN2Tf/XLHmep6pjNcp79MeqrjqhhU88pBtu\nHCLf13zKf3ajfv3z30a6VKBVjh6v0qTsf1Hvnj2aPxsyeKByc+ZFsCqEIsry+/AIvHbkmv7Jmrto\npjJve0DVVbXKvOcuPbFqgd7bU67YuBhNHJctf9LVKty6Tu/t+UCVFccjXTLQKolXJ+i1F/4j0mXg\nK2JLE8b0H9BXhz+qVHVVrSRp15/e1XUD+ylt9Df1i+JtCgQCqjpeoze3v630W0dFuFoAsEurOryz\nZ8+qtvYf/8gmJiYqLi4urEXhi+1998/qk9xT1w3spwP7/1cZt9+inW+/o97JPdQhqkPzn6s/26A+\n1/SKYKVA25ytr9fcR5fpo4oj6tE9ST/4/gxd2zc50mWhjdr1lOYHH3yg5cuXq66uTl27dlUgEFB1\ndbWSkpK0dOlSDRo06HLVCUk11Se0etV6/ee2Dao/26CG+gbdN+Uh3f29O5WVPUmlb+9Rt4QuGjt+\ntN4pey/S5QKtEhcbq9vGjlH2lLvV3Z+owuLXNffRZSre9Lx8HToEvR72sDzvWg68vLw8LV++XP37\n97/o83379mnZsmUqLCwMa3G42OAhAzRj9jRNGP09HT9arTsm36rVP8vTPXfN1IInHlTxbzaq4lCl\n3t5RpvOffRbpcoFW6dL5KuU8OKv5/b2Zk7W+YIsOV1Tq2mvo8mBOi2d4gUDgkrCTpCFDhqipqSls\nReGLfWvkCL33TrmOH62WJJX88ne6bmA/xcR21OPzn9Jd6ffq36YvUFx8rP72l79HuFqgdepOn1bl\nsYsHrJqaLsjno7trb6I8L+TX5dBih3f99ddr5syZysjIULdu3SRJtbW1Kikp0U033XRZCsQ/fXSw\nQlnZk9W5y1X65OM6jUr/tmqqT2jSlAnqdnVXPfPkT3TtgL769sgb9XRufqTLBVpl31//puU/XqMX\n859T1y6d9dqvf6Pu/kT16tE90qWhjWz/eqAWA2/hwoXavXu3SktLtXfvXkmS3+/X7NmzNXz48MtS\nIP7prTf+pG8MHagXf/4TKRDQmTP1mvf9x3TooyN6au1j+q8/vKTGxnNaPDdPp+vORLpcoFXSvjlC\nmXfdofse/IGioqKUeHWCVj2+WB04v2t3bL8twQsEAoFw/oBhfW8J5/LAZVH6x42RLgEwIr73pcdU\npiwavzDka/NKVhis5Itx4zkAwIh2fVsCAACtZXne8aQVAIAb6PAAAEawpQkAcEK7vi0BAIDWsr3D\n4wwPAOAEOjwAgBGWN3h0eAAAN9DhAQCMsP3RYgQeAMAI24dWCDwAgBGW5x2BBwAww/YOj6EVAIAT\nCDwAgBPY0gQAGBHOR4tt3bpVGzZskM/n04MPPqhBgwZp/vz5ampqUmJiolatWqXo6OgW16DDAwAY\n4XleyK+WnDp1Svn5+dqyZYvWrVunN954Q6tXr9bUqVO1ZcsW9e3bV8XFxUHrI/AAAEZEeaG/WlJa\nWqq0tDR16tRJfr9fubm5Kisr07hx4yRJ6enpKi0tDVofW5oAACPCdeP5kSNH1NjYqJkzZ6qurk5z\n5sxRQ0ND8xZmQkKCampqgq5D4AEArPfxxx9r7dq1Onr0qLKzsxUIBJp/7/O/bglbmgAAqyUkJGj4\n8OHy+XxKTk5WfHy84uPj1djYKEmqqqqS3+8Pug6BBwAwIlxDK6NGjdLOnTt14cIFnTp1SvX19br5\n5ptVUlIiSdq+fbtGjx4dtD62NAEARgQbPglVUlKSxo8frylTpkiSlixZoqFDh2rBggUqKipSz549\nNWnSpKDrEHgAACPC+W0JWVlZysrKuuizTZs2tWkNAg8AYITlj9LkDA8A4AY6PACAEXxbAgAAFqDD\nAwAYEc6HR5tA4AEAjLB8R5PAAwCYwRkeAAAWoMMDABgRzhvPTSDwAABGWJ53bGkCANxAhwcAMIIt\nTQCAE8L1bQmmsKUJAHACHR4AwAi2NAEATrA87wg8AIAZPGkFAAAL0OEBAIyw/QyPDg8A4AQ6PACA\nEZY3eAQeAMAM27c0CTwAgBGW5x2BBwAwg9sSAACwAIEHAHACW5oAACMs39Ek8AAAZjClCQBwguV5\nR+ABAMywvcNjaAUA4AQCDwDgBLY0AQBGWL6jSeABAMyw/UkrBB4AwAjL847AAwCYwZQmAAAWoMMD\nABhheYNHhwcAcAMdHgDACNvP8Ag8AIARlucdgQcAMCPcHV5jY6PuvPNOzZo1S7t27dK+ffvUpUsX\nSdIDDzygMWPGtHg9gQcAaBd++tOfqnPnzs3v586dq/T09FZfT+ABAIwIZ4N38OBBHThwIGgX1xKm\nNAEARnieF/IrmJUrVyonJ+eizwoKCpSdna1HHnlEJ0+eDLoGgQcAsNrrr7+uG264QX369Gn+bOLE\niZo3b542b96slJQUrV27Nug6bGkCAIwI15bmjh07VFFRoR07duj48eOKjo7WsmXLlJKSIkkaO3as\nHn/88aDrhD3w9nzwWrh/BBB2v1xYEOkSACPuzn8obGuH69sSnnvuueZfr1mzRr169dJLL72kPn36\nqE+fPiorK9OAAQOCrkOHBwAw4nLeh3fPPffo4YcfVmxsrOLi4rRixYqg1xB4AIB2Y86cOc2/fvXV\nV9t0LYEHADCCR4sBAJxged5xWwIAwA10eAAAI7wou1s8Ag8AYARbmgAAWIAODwBgBFOaAAAnWJ53\nBB4AwAzbOzzO8AAATqDDAwAYYXmDR4cHAHADHR4AwAzLWzwCDwBghO1DKwQeAMAIy/OOwAMAmGH7\nszQZWgEAOIHAAwA4gS1NAIARnOEBAJzAlCYAwAmW5x2BBwAww/YOj6EVAIATCDwAgBPY0gQAGGH5\njiaBBwAww/YzPAIPAGCG5YdkBB4AwAjbOzzL8xgAADMIPACAE9jSBAAYYfmOJoEHADDD9jM8Ag8A\nYITleUfgAQAMsTzxGFoBADiBDg8AYIQXRYcHAEDE0eEBAIyw/AiPwAMAmMFtCQAAJ1ied5zhAQDc\nQIcHADAjTC1eQ0ODcnJydOLECZ07d06zZs3S4MGDNX/+fDU1NSkxMVGrVq1SdHR0i+sQeAAAI8J1\nW8Kbb76p1NRUzZgxQ5WVlbr//vs1YsQITZ06VbfffrueffZZFRcXa+rUqS2uw5YmAMBqEyZM0IwZ\nMyRJx44dU1JSksrKyjRu3DhJUnp6ukpLS4OuQ4cHADAi3EMrWVlZOn78uNatW6f77ruveQszISFB\nNTU1Qa8n8AAAZoQ58V5++WV9+OGH+uEPf6hAIND8+ed/3RK2NAEAVisvL9exY8ckSSkpKWpqalJ8\nfLwaGxslSVVVVfL7/UHXIfAAAEZ4XuivluzZs0cbN26UJNXW1qq+vl4333yzSkpKJEnbt2/X6NGj\ng9bHliYAwIhwTWlmZWVp8eLFmjp1qhobG7V06VKlpqZqwYIFKioqUs+ePTVp0qSg6xB4AAAjwvVo\nsZiYGD3zzDOXfL5p06Y2rcOWJgDACXR4AAAzeJYmAACRR4cHADCCrwcCADiBwAMAuMHyQzICDwBg\nhO0dnuV5DACAGQQeAMAJbGkCAIywfUuTwAMAmGF33hF4AAAzwvXwaFMIPACAGZZvaTK0AgBwAoEH\nAHACW5rtXNnuPXrm39eqvqFBPbp3V+7SxeqeFPyr7gFbdB9yjUbOmqhtj27UubONuiFzjBKu7aGo\nDlHa96tSVez+a6RLRCtZvqNJh9ee1Tc0aP7ipXp8yUL96tUijRk9Urk/eirSZQGt1uFrPqVOHKlz\nZxokSSm33SRfR5+2527WWz8u1tBJoxSXcFWEq0RreZ4X8utyIPDasV2731HvXr30jcGDJEmT77pT\nf9q5S2fPno1wZUDrpNzxLR3e9RedP/eZJMk/OFmHdn4oBaSGj8/o6N6/q+ewayNcJVotygv9dTnK\nC/XCuro6k3UgBIcOH1bvXr2a38fFxalL5846fORIBKsCWueqnglKGpysv/3ufz73aeCi/9s/f+5T\ndUrscvmLQ0iu2A5v9uzZJutACBoaz6ljx+iLPuvYsaMaGhojVBHQesOzxuq9V95S4MKF5s+q/1Kh\na28ZpihfB8V2/bp6XX+donwdIlglriQtDq0UFhZ+6e9VVVUZLwZtExsbo3PnPr3os8bGRsXFxkao\nIqB1+o1K1enjJ3Xi4NGLPv9wW5muzxyjjEX36GztJzr+54904XxThKpEm1k+tNJi4L3wwgtKS0uT\n33/p1N/58+fDVhRap981fVXy2zea358+c0Z1p08rOblPBKsCgus5rL+6JPt1x9B+kqSOnWI1dn6W\nyn62Te8W/nfzn7vx3gzVHK6OVJm4wrQYePn5+XryySe1ZMkSRUdfvHVWVlYW1sIQ3E033qily/L0\n7nvva8QN1+vFLS/rllEj6fBgvT/+5BcXvb9t2X36/XPF6n3jQHUf2k8fvPYHfb17N/kHJWvvq7+P\nUJVoq3b98OiBAwfq+eefl8936R/LyckJW1FonZiYjlqVt0zLn3pGDQ0NSu7dW08+tiTSZQEhO7Tz\nQ910/2267YnpavrsvHZvLtFnDZ8GvxBWsP1Zml4gEAiE8wd8WncinMsDl8UvFxZEugTAiLvzHwrb\n2hW/3hbytX3uuN1gJV+MJ60AAIywfUuTG88BAE6gwwMAmGF3g0eHBwBwAx0eAMAI26c0CTwAgBmW\nD60QeAAAI5jSBADAAnR4AAAzOMMDALiALU0AACxAhwcAMMPuBo/AAwCYwZYmAAAWoMMDAJjBlCYA\nwAW2b2kSeAAAMywPPM7wAADW279/vzIyMlRQUCBJysnJ0Xe+8x1NmzZN06ZN044dO4KuQYcHADAi\nXFua9fX1ys3NVVpa2kWfz507V+np6a1ehw4PAGC16OhorV+/Xn6//yutQ+ABAMyI8kJ/tcDn8ykm\nJuaSzwsKCpSdna1HHnlEJ0+eDF5eyH8xAAA+x/O8kF9tNXHiRM2bN0+bN29WSkqK1q5dG/QaAg8A\nYIbnhf5qo7S0NKWkpEiSxo4dq/379we9hsADABjhRXkhv9pqzpw5qqiokCSVlZVpwIABQa9hShMA\nYLXy8nKtXLlSlZWV8vl8Kikp0b333quHH35YsbGxiouL04oVK4KuQ+ABAKyWmpqqF1988ZLPx48f\n36Z1CDwAgBmWP2mFwAMAGMGzNAEAbiDwAAAuCGXa8nLitgQAgBMIPACAE9jSBACYwRkeAMAJBB4A\nwAXclgAAcANTmgAARB4dHgDACM+zu4eyuzoAAAyhwwMAmMHQCgDABUxpAgDcwJQmAACRR4cHADCC\nLU0AgBssDzy2NAEATqDDAwCYYfmN5wQeAMAIvvEcAAAL0OEBAMywfGiFwAMAGMFtCQAAN1g+tGJ3\ndQAAGEKHBwAwgilNAAAsQIcHADCDoRUAgAuY0gQAuMHyKU0CDwBgBkMrAABEHoEHAHACW5oAACMY\nWgEAuIGhFQCAC+jwAABusLzDs7s6AAAMIfAAAE5gSxMAYEQ4vy0hLy9P77//vjzP06JFizRs2LA2\nr0HgAQDMCNPQyq5du3To0CEVFRXp4MGDWrRokYqKitq8DoEHADDCC9PQSmlpqTIyMiRJ/fv31yef\nfKIzZ86oU6dObVqHMzwAgBmeF/qrBbW1teratWvz+27duqmmpqbN5YW9w4u+KiHcPwIIu7vzH4p0\nCYD1Lte/94FAIKTr6PAAAFbz+/2qra1tfl9dXa3ExMQ2r0PgAQCsNnLkSJWUlEiS9u3bJ7/f3+bz\nO4mhFQCA5UaMGKEhQ4YoKytLnufpscceC2kdLxDqZigAAO0IW5oAACcQeAAAJxB47VxeXp6++93v\nKisrS3v37o10OUDI9u/fr4yMDBUUFES6FFyhGFppx0w9bgeItPr6euXm5iotLS3SpeAKRofXjn3Z\n43aA9iY6Olrr16+X3++PdCm4ghF47Zipx+0Akebz+RQTExPpMnCFI/CuINxhAgBfjsBrx0w9bgcA\nXEDgtWOmHrcDAC7gSSvt3NNPP609e/Y0P25n8ODBkS4JaLPy8nKtXLlSlZWV8vl8SkpK0po1a9Sl\nS5dIl4YrCIEHAHACW5oAACcQeAAAJxB4AAAnEHgAACcQeAAAJxB4AAAnEHgAACcQeAAAJ/wf4lZL\nW+pOUFMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}